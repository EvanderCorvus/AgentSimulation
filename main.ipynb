{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tr\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = tr.device('cuda' if tr.cuda.is_available() else 'cpu')\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Force Field\n",
    "\n",
    "# X,Y = np.linspace(-0.75,0.75,43),np.linspace(-0.75,0.75,43)\n",
    "\n",
    "# # def U(x,y,U_0=0.4): #potential function, U_0 is the amplitude, x and y are the coordinates, Gradient needs to be calculated manually in forward pass.\n",
    "# #     if (x**2+y**2)**0.5<=0.5:\n",
    "# #         return tr.tensor((16*U_0*((x**2+y**2)**0.5-0.25)**2),dtype=tr.half)\n",
    "# #     else:\n",
    "# #         return tr.tensor(0,dtype=tr.half)\n",
    "\n",
    "# def U(x,y,U_0=0.4): #potential function, U_0 is the amplitude, x and y are the coordinates, Gradient needs to be calculated manually in forward pass.\n",
    "#     if (x**2+y**2)**0.5<=0.5:\n",
    "#         return 16*U_0*((x**2+y**2)**0.5-0.25)**2\n",
    "#     else:\n",
    "#         return 0\n",
    "# # Z = U(X,Y)\n",
    "# # F = tr.from_numpy(np.gradient(Z))\n",
    "# # print(F.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "tensor([1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# #Toy Force Field\n",
    "# x = np.linspace(-0.75, 0.75, 100)\n",
    "# y = np.linspace(-0.75, 0.75, 100)\n",
    "# X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# # Calculate the force field\n",
    "# force_field_x = -np.abs(Y)\n",
    "# force_field_y = np.zeros_like(X)\n",
    "\n",
    "# # Create the meshgrid for force field\n",
    "# F = tr.tensor(tr.from_numpy(np.stack((force_field_x, force_field_y), axis=2)),dtype=tr.float)\n",
    "\n",
    "t1=tr.tensor([1,1],dtype=tr.float)\n",
    "t2=tr.tensor([1],dtype=tr.float)\n",
    "print(t2.shape)\n",
    "t3=tr.tensor([1],dtype=tr.float)\n",
    "T = tr.cat([t1,t2,t3])\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent Class\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, x=tr.tensor([-0.5], dtype=tr.float), y=tr.tensor([0],dtype=tr.float), b=tr.tensor([0],dtype=tr.float)):#initialize agent at location (-0.5,-0.5)\n",
    "        super(Agent, self).__init__()\n",
    "        self.x=x #x coordinate\n",
    "        self.y=y #y coordinate\n",
    "        self.b=b #bias\n",
    "        self.input = nn.Linear(5, 64,dtype=tr.float) #input layer\n",
    "        self.hidden1 = nn.Linear(64, 64,dtype=tr.float) #hidden layer\n",
    "        self.hidden2 = nn.Linear(64, 32, dtype = tr.float) #hidden layer\n",
    "        self.output = nn.Linear(32, 4,dtype=tr.float) \n",
    "        self.activation = nn.ReLU() #activation function\n",
    "\n",
    "    def forward(self, x, network = None): #forward pass\n",
    "        if network is None: network = self\n",
    "        x1 = self.activation(self.input(x))\n",
    "        x2 = self.activation(self.hidden1(x1))\n",
    "        x3 = self.activation(self.hidden2(x2))\n",
    "        x4 = self.activation(self.output(x3))\n",
    "        return x4\n",
    "    \n",
    "\n",
    "    def move(self,Q,e):\n",
    "        if tr.rand(size=(1,))<e:\n",
    "            L = tr.randint(0, 4, (1,))\n",
    "        else: L = tr.argmax(Q)\n",
    "        \n",
    "        dx,dy = 0.,0.\n",
    "        if L==0: dx = 0.0357 #up\n",
    "        elif L==1: dx = -0.0357 #down\n",
    "        elif L==2: dy = 0.0357 #right\n",
    "        elif L==3: dy = -0.0357 #left\n",
    "        else: raise Exception('Invalid action')\n",
    "\n",
    "        if (-0.75<=self.x+dx<=0.75).item() == False:\n",
    "            dx=0\n",
    "        if (-0.75<=self.y+dy<=0.75).item() == False:\n",
    "            dy=0\n",
    "        self.x+=dx\n",
    "        self.y+=dy\n",
    "        # if dx == dy == 0: raise Exception('Agent did not move')\n",
    "def R(x,y,F):\n",
    "    dt = 1/(F+1e-8)\n",
    "    return -0.5*dt/1000-0.5*tr.norm(tr.tensor([x-0.5,y]),p=2)\n",
    "\n",
    "# def R(x,y):\n",
    "#     return -tr.norm(tr.tensor([x-0.5,y]),p=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # toy = Agent()\n",
    "# # print(toy.x,toy.x.shape)\n",
    "# a=tr.tensor([-0.5], dtype=tr.float)\n",
    "# print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5000]) tensor([0.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 3) cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[415], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mif\u001b[39;00m dT\u001b[39m%\u001b[39mt_update\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\u001b[39m#update target agent every 100 steps\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     t_agent\u001b[39m.\u001b[39mload_state_dict(agent\u001b[39m.\u001b[39mstate_dict())\n\u001b[1;32m---> 28\u001b[0m s \u001b[39m=\u001b[39m tr\u001b[39m.\u001b[39;49mcat([agent\u001b[39m.\u001b[39;49mx, agent\u001b[39m.\u001b[39;49my, \u001b[39m-\u001b[39;49mtr\u001b[39m.\u001b[39;49mabs(agent\u001b[39m.\u001b[39;49my), tr\u001b[39m.\u001b[39;49mtensor(\u001b[39m0\u001b[39;49m,dtype\u001b[39m=\u001b[39;49mtr\u001b[39m.\u001b[39;49mfloat), agent\u001b[39m.\u001b[39;49mb])\u001b[39m.\u001b[39mto(device) \u001b[39m#state\u001b[39;00m\n\u001b[0;32m     29\u001b[0m Q1 \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39mforward(s) \u001b[39m#Q value\u001b[39;00m\n\u001b[0;32m     30\u001b[0m e \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m-\u001b[39mdT\u001b[39m/\u001b[39mmax_steps \u001b[39m#epsilon\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 3) cannot be concatenated"
     ]
    }
   ],
   "source": [
    "#Simulation\n",
    "agent = Agent().to(device)\n",
    "\n",
    "t_agent = Agent().to(device)\n",
    "t_agent.load_state_dict(agent.state_dict())\n",
    "\n",
    "t_agent.eval()\n",
    "\n",
    "t_update = 100\n",
    "optimizer = tr.optim.Adam(agent.parameters(), lr=0.001)\n",
    "dT = 0\n",
    "g = 0.8\n",
    "max_steps = 2000\n",
    "X,Y=[],[]\n",
    "print(agent.x,agent.y)\n",
    "\n",
    "\n",
    "while dT<max_steps:\n",
    "    \n",
    "    x0,y0 = agent.x.numpy(),agent.y.numpy()\n",
    "    X.append(agent.x.numpy())\n",
    "    Y.append(agent.y.numpy())\n",
    "    dT+=1\n",
    "    if dT%t_update==0:#update target agent every 100 steps\n",
    "        t_agent.load_state_dict(agent.state_dict())\n",
    "    \n",
    "\n",
    "    s = tr.cat([agent.x, agent.y, -tr.abs(agent.y), tr.tensor(0,dtype=tr.float), agent.b]).to(device) #state\n",
    "    Q1 = agent.forward(s) #Q value\n",
    "    e = 1-dT/max_steps #epsilon\n",
    "    agent.move(Q1,tr.tensor(e,dtype=tr.float))      \t    #move agent\n",
    "    x1,y1 = agent.x.numpy(),agent.y.numpy()\n",
    "    if np.abs(x0-x1)>0.0357 or np.abs(y1-y0)>0.0357: raise Exception('Agent moved too far')\n",
    "\n",
    "\n",
    "    s2 = tr.cat([agent.x, agent.y, -tr.abs(agent.y), tr.tensor(0,dtype=tr.float), agent.b]).to(device) #state\n",
    "    Q2 = agent.forward(s2,network=t_agent) #Q value\n",
    "    tQ = R(agent.x,agent.y,agent.y)+ g*tr.max(Q2)         #target Q value\n",
    "    criterion = nn.MSELoss().to(device)     #1/2*(tQ-Q1)**2 #loss\n",
    "    loss = criterion(tQ,tr.max(Q1))         #loss\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()                   #zero gradients\n",
    "    loss.backward()                         #backpropagate\n",
    "    optimizer.step()                        #update weights\n",
    "    if (tr.round(agent.x,decimals = 1),tr.round(agent.y,decimals = 1)) == (0.5000,0.0000):\n",
    "        print('success')\n",
    "        break\n",
    "print(agent.x,agent.y,np.var(X),np.var(Y))\n",
    "# print(tr.round(agent.x,decimals = 1),tr.round(agent.y,decimals = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 = tr.stack(X).numpy()\n",
    "# Y1 = tr.stack(Y).numpy()\n",
    "\n",
    "# plt.scatter(X,Y)\n",
    "# plt.xlim(-0.75,0.75)\n",
    "# plt.ylim(-0.75,0.75)\n",
    "# plt.grid()\n",
    "# plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
