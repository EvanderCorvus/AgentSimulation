{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tr\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = tr.device('cuda' if tr.cuda.is_available() else 'cpu')\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 0.])\n"
     ]
    }
   ],
   "source": [
    "# #Force Field\n",
    "\n",
    "# X,Y = np.linspace(-0.75,0.75,43),np.linspace(-0.75,0.75,43)\n",
    "\n",
    "# # def U(x,y,U_0=0.4): #potential function, U_0 is the amplitude, x and y are the coordinates, Gradient needs to be calculated manually in forward pass.\n",
    "# #     if (x**2+y**2)**0.5<=0.5:\n",
    "# #         return tr.tensor((16*U_0*((x**2+y**2)**0.5-0.25)**2),dtype=tr.half)\n",
    "# #     else:\n",
    "# #         return tr.tensor(0,dtype=tr.half)\n",
    "\n",
    "# def U(x,y,U_0=0.4): #potential function, U_0 is the amplitude, x and y are the coordinates, Gradient needs to be calculated manually in forward pass.\n",
    "#     if (x**2+y**2)**0.5<=0.5:\n",
    "#         return 16*U_0*((x**2+y**2)**0.5-0.25)**2\n",
    "#     else:\n",
    "#         return 0\n",
    "# # Z = U(X,Y)\n",
    "# # F = tr.from_numpy(np.gradient(Z))\n",
    "# # print(F.shape)\n",
    "dr = tr.tensor([1,0],dtype=tr.float)\n",
    "dr *=2\n",
    "print(dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# #Toy Force Field\n",
    "# x = np.linspace(-0.75, 0.75, 100)\n",
    "# y = np.linspace(-0.75, 0.75, 100)\n",
    "# X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# # Calculate the force field\n",
    "# force_field_x = -np.abs(Y)\n",
    "# force_field_y = np.zeros_like(X)\n",
    "\n",
    "# # Create the meshgrid for force field\n",
    "# F = tr.tensor(tr.from_numpy(np.stack((force_field_x, force_field_y), axis=2)),dtype=tr.float)\n",
    "\n",
    "t1=tr.tensor(1,dtype=tr.float)\n",
    "t2=tr.tensor(1,dtype=tr.float)\n",
    "t1-=t2\n",
    "print(t1)\n",
    "T = tr.stack([t1,t2])\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent Class\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, x=tr.tensor(-0.5, dtype=tr.float), y=tr.tensor(0,dtype=tr.float), b=tr.tensor(0,dtype=tr.float)):#initialize agent at location (-0.5,-0.5)\n",
    "        super(Agent, self).__init__()\n",
    "        self.x=x #x coordinate\n",
    "        self.y=y #y coordinate\n",
    "        self.b=b #bias\n",
    "        self.input = nn.Linear(5, 64,dtype=tr.float) #input layer\n",
    "        self.hidden1 = nn.Linear(64, 64,dtype=tr.float) #hidden layer\n",
    "        self.hidden2 = nn.Linear(64, 32, dtype = tr.float) #hidden layer\n",
    "        self.output = nn.Linear(32, 4,dtype=tr.float) \n",
    "        self.activation = nn.ReLU() #activation function\n",
    "\n",
    "    def forward(self, x, network = None): #forward pass\n",
    "        if network is None: network = self\n",
    "        x1 = self.activation(self.input(x))\n",
    "        x2 = self.activation(self.hidden1(x1))\n",
    "        x3 = self.activation(self.hidden2(x2))\n",
    "        x4 = self.activation(self.output(x3))\n",
    "        return x4\n",
    "    \n",
    "\n",
    "    def move(self,Q,e):\n",
    "        if tr.rand(size=(1,))<e:\n",
    "            L = tr.randint(0, 4, (1,))\n",
    "        else: L = tr.argmax(Q)\n",
    "        \n",
    "        dx,dy = tr.tensor(0.,dtype=tr.float),tr.tensor(0.,dtype=tr.float)\n",
    "        a = tr.tensor(0.0357,dtype=tr.float)\n",
    "        if L.item()==0: dy = a #up\n",
    "        elif L.item()==1: dy = -a #down\n",
    "        elif L.item()==2: dx = a #right\n",
    "        elif L.item()==3: dx = -a #left\n",
    "        else: raise Exception('Invalid action')\n",
    "        if (-0.75<=self.x<=0.75).item() == False: raise Exception('Invalid x coordinate')\n",
    "        if (-0.75<=self.y<=0.75).item() == False: raise Exception('Invalid y coordinate')\n",
    "        \n",
    "        if (-0.75<=self.x+dx<=0.75).item() == False:\n",
    "            dx=0\n",
    "        if (-0.75<=self.y+dy<=0.75).item() == False:\n",
    "            dy=0\n",
    "        self.x+=dx\n",
    "        self.y+=dy\n",
    "        #if dx == dy == 0: print('stuck')\n",
    "\n",
    "def R(x,y,F,L):#Reward function, F is the force field, L is the action\n",
    "    u = tr.tensor([-1,0],dtype=tr.float).to(device) #normalized Force Field\n",
    "    dx,dy = 0,0\n",
    "    if L.item()==0 or L.item()==1: dy = 1\n",
    "    elif L.item()==2 or L.item()==3: dx = 1\n",
    "    else: raise Exception('Invalid action')\n",
    "\n",
    "    dr = tr.tensor([dx,dy],dtype=tr.float).to(device)\n",
    "    e = dr - u/tr.norm(dr-u,p=2)\n",
    "    dr*=0.0357\n",
    "    dt = 0.0357/tr.dot((e+F),dr).item()\n",
    "    r = -0.5*dt/1000-0.5*tr.norm(tr.tensor([x-0.5,y]),p=2)\n",
    "    if r.shape != tr.Size([]): raise Exception('Reward is not a scalar')\n",
    "    return r\n",
    "\n",
    "# def R(x,y):\n",
    "#     return -tr.norm(tr.tensor([x-0.5,y]),p=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.5000) tensor(0.)\n",
      "tensor(-0.3929) tensor(0.4998)\n",
      "tensor(-0.3572) tensor(0.7497)\n",
      "tensor(-0.7142) tensor(0.6783)\n",
      "tensor(-0.4643) tensor(0.7497)\n",
      "tensor(-0.5357) tensor(0.6426)\n",
      "tensor(-0.7142) tensor(0.7497)\n",
      "tensor(-0.4643) tensor(0.6783)\n",
      "tensor(-0.6785) tensor(0.7497)\n",
      "tensor(-0.4643) tensor(0.7140)\n",
      "tensor(-0.3215) tensor(0.7497)\n",
      "tensor(-0.1430) tensor(0.7497)\n",
      "tensor(-0.0716) tensor(0.7497)\n",
      "tensor(-0.2144) tensor(0.7497)\n",
      "tensor(-0.1430) tensor(0.7497)\n",
      "tensor(-0.1073) tensor(0.7497)\n",
      "tensor(-0.3929) tensor(0.7497)\n",
      "tensor(-0.5714) tensor(0.7497)\n",
      "tensor(-0.5357) tensor(0.7497)\n",
      "tensor(-0.5714) tensor(0.7497)\n",
      "tensor(-0.6071) tensor(0.7497)\n",
      "tensor(-0.6071) tensor(0.7497)\n"
     ]
    }
   ],
   "source": [
    "#Simulation\n",
    "agent = Agent().to(device)\n",
    "\n",
    "t_agent = Agent().to(device)\n",
    "t_agent.load_state_dict(agent.state_dict())\n",
    "\n",
    "t_agent.eval()\n",
    "\n",
    "t_update = 100\n",
    "optimizer = tr.optim.Adam(agent.parameters(), lr=0.001)\n",
    "dT = 0\n",
    "g = 0.8\n",
    "max_steps = 2000\n",
    "X,Y=[],[]\n",
    "print(agent.x,agent.y)\n",
    "\n",
    "\n",
    "while dT<max_steps:\n",
    "    \n",
    "    x0,y0 = agent.x.numpy(),agent.y.numpy()\n",
    "    X.append(agent.x.numpy())\n",
    "    Y.append(agent.y.numpy())\n",
    "    dT+=1\n",
    "    if dT%t_update==0:#update target agent every 100 steps\n",
    "        t_agent.load_state_dict(agent.state_dict())\n",
    "        print(agent.x,agent.y)\n",
    "\n",
    "\n",
    "    s = tr.stack([agent.x, agent.y, -tr.abs(agent.y), tr.tensor(0,dtype=tr.float), agent.b]).to(device) #state\n",
    "    Q1 = agent.forward(s) #Q value\n",
    "    e = 1-dT/max_steps #epsilon\n",
    "    agent.move(Q1,tr.tensor(e,dtype=tr.float))      \t    #move agent\n",
    "    x1,y1 = agent.x.numpy(),agent.y.numpy()\n",
    "    if np.abs(x0-x1)>0.0357 or np.abs(y1-y0)>0.0357: raise Exception('Agent moved too far')\n",
    "\n",
    "\n",
    "    s2 = tr.stack([agent.x, agent.y, -tr.abs(agent.y), tr.tensor(0,dtype=tr.float), agent.b]).to(device) #state\n",
    "    Q2 = agent.forward(s2,network=t_agent) #Q value\n",
    "    \n",
    "    F = tr.tensor([-agent.y,0],dtype=tr.float).to(device)\n",
    "    tQ = R(agent.x.to(device), agent.y.to(device), F, tr.argmax(Q1))+ g*tr.max(Q2)         #target Q value\n",
    "    criterion = nn.MSELoss().to(device)     #1/2*(tQ-Q1)**2 #loss\n",
    "    loss = criterion(tQ,tr.max(Q1))         #loss\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()                   #zero gradients\n",
    "    loss.backward()                         #backpropagate\n",
    "    optimizer.step()                        #update weights\n",
    "    if (tr.round(agent.x,decimals = 2),tr.round(agent.y,decimals = 2)) == (0.5000,0.0000):\n",
    "        print('success')\n",
    "        break\n",
    "print(agent.x,agent.y)\n",
    "# print(tr.round(agent.x,decimals = 1),tr.round(agent.y,decimals = 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
